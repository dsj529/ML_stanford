# ML_stanford
Coding exercises for Andrew Ng's Machine Learning course from Stanford University, taken via Coursera.com

Code written in Octave 4.2.1

* Ex1: Implementation of Linear Regression, with parameters learned via Gradient Descent and Normal Equation solutions.  Implementations for both single and multiple variable regressions.

* Ex2: Implementation of Logistic Regression, using Gradient Descent to learn parameters.  Also contains implementation of regularized parameter learning.

* Ex3: Implementation of multiclass (one-vs-all) Logistic Regression.  Implementation of forward-feed Neural Network.

* Ex4: Implementation of back-propagation algorithm within neural network architectures.

* Ex5: Implementation of regularized mutivariate linear regression.  Also implementation of performance evaluation techniques to diagnose overfit/underfit due to high variance or bias.

* Ex6: Implementation of Support Vector Machines using LIBSVM and a Gaussian/RBF kernel function.
